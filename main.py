import streamlit as st
import pandas as pd
import os

# -------------------------------------------------------
# Í∏∞Î≥∏ ÏÑ§Ï†ï
# -------------------------------------------------------
st.set_page_config(page_title="Urantia Theme Study", layout="wide")
st.title("üìò Urantia Theme Study")
st.caption("Keyword search + Glossary lookup + AI study draft (stable version)")

# -------------------------------------------------------
# ÌååÏùº Í≤ΩÎ°ú
# -------------------------------------------------------
EN_PATH = os.path.join("data", "urantia_en.txt")
GLOSS_PATH = os.path.join("data", "English_Master_Glossary.xlsx")

# -------------------------------------------------------
# ÏòÅÏñ¥ Î≥∏Î¨∏ Î°úÎìú
# -------------------------------------------------------
@st.cache_data
def load_text():
    encodings = ["utf-8", "utf-8-sig", "cp949", "latin-1"]
    for enc in encodings:
        try:
            with open(EN_PATH, "r", encoding=enc) as f:
                return [line.strip() for line in f if line.strip()]
        except Exception:
            continue
    return []

# -------------------------------------------------------
# Ïö©Ïñ¥Ïßë Î°úÎìú (ÏûêÎèô Ïª¨Îüº Ï†ïÎ¶¨)
# -------------------------------------------------------
@st.cache_data
def load_glossary():
    try:
        df = pd.read_excel(GLOSS_PATH)
        raw_cols = list(df.columns)
        # ÏÜåÎ¨∏Ïûê+Í≥µÎ∞±Ï†úÍ±∞
        df.columns = [c.strip().lower() for c in df.columns]

        # Ïª¨Îüº ÏûêÎèô Í∞êÏßÄ
        if "term" not in df.columns or "definition" not in df.columns:
            if len(df.columns) == 2:
                df.rename(columns={
                    df.columns[0]: "term",
                    df.columns[1]: "definition"
                }, inplace=True)
            else:
                for c in df.columns:
                    if "term" in c: df.rename(columns={c: "term"}, inplace=True)
                    if "def" in c or "desc" in c: df.rename(columns={c: "definition"}, inplace=True)

        df["term"] = df["term"].astype(str).str.strip().str.lower()
        df["definition"] = df["definition"].astype(str).str.strip()

        return df, raw_cols
    except Exception as e:
        st.error(f"‚ö†Ô∏è Glossary load error: {e}")
        return None, []

# -------------------------------------------------------
# Îç∞Ïù¥ÌÑ∞ Î°úÎìú
# -------------------------------------------------------
text_lines = load_text()
glossary, raw_cols = load_glossary()

st.markdown("### üì¶ Data Status")
st.write(f"üìÅ data/ folder exists: {os.path.exists('data')}")
st.write(f"üìÑ urantia_en.txt lines: {len(text_lines)}")
st.write(f"üìÑ glossary columns: {raw_cols if raw_cols else '‚ùå not loaded'}")

# -------------------------------------------------------
# Í≤ÄÏÉâ ÏûÖÎ†•
# -------------------------------------------------------
term = st.text_input("üîç Enter keyword or theme (e.g., Thought Adjuster, faith, Michael)").strip()

# -------------------------------------------------------
# Í≤ÄÏÉâ Ïã§Ìñâ
# -------------------------------------------------------
if term:
    st.markdown("---")

    # 1Ô∏è‚É£ Glossary Lookup
    st.subheader("1. Glossary Lookup")
    if glossary is not None and len(glossary) > 0:
        found = glossary[glossary["term"].str.contains(term.lower(), case=False, na=False)]
        if len(found) > 0:
            for _, row in found.iterrows():
                st.markdown(f"**{row['term'].capitalize()}** ‚Äî {row['definition']}")
        else:
            st.info("No glossary match found for this term.")
    else:
        st.warning("Glossary not loaded or invalid structure.")

    # 2Ô∏è‚É£ Urantia Book Search
    st.subheader("2. Passages in The Urantia Book")
    matches = [line for line in text_lines if term.lower() in line.lower()]
    if matches:
        for m in matches[:10]:
            st.markdown(f"üîπ {m}")
    else:
        st.info("No passages found in urantia_en.txt containing that keyword.")

    # 3Ô∏è‚É£ Topic importance
    st.subheader("3. Topic importance check")
    if len(matches) < 2 and len(term.split()) < 2:
        st.info("This topic seems too short or rare for an AI summary.")
    else:
        st.success("‚úÖ Enough material for AI-based study expansion later.")

    # 4Ô∏è‚É£ AI Study (Placeholder)
    st.subheader("4. AI study material")
    st.info("AI explanation & PPT builder (GPT + Gamma) will appear here.")
else:
    st.info("Please enter a keyword above to begin searching.")











